{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pystac_client import Client\n",
    "from odc.stac import load, configure_s3_access\n",
    "from odc.algo import mask_cleanup\n",
    "from dask.distributed import Client as DaskClient\n",
    "from pathlib import Path\n",
    "from numpy import nanpercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = gpd.read_file('areas.geojson')\n",
    "# Strip newlines\n",
    "areas[\"Capital\"] = areas[\"Capital\"].str.strip()\n",
    "areas[\"Country\"] = areas[\"Country\"].str.strip()\n",
    "areas[\"Name\"] = areas[\"Name\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic_region(\n",
    "    area,\n",
    "    overwrite=True,\n",
    "    sentinel2=True,\n",
    "    catalog=\"https://earth-search.aws.element84.com/v1\",\n",
    "    year=\"2024\",\n",
    "    write_data=False,\n",
    "):\n",
    "    client = Client.open(catalog)\n",
    "    country = area.Country.lower().replace(\" \", \"_\")\n",
    "    if sentinel2:\n",
    "        sensor = \"s2\"\n",
    "    else:\n",
    "        sensor = \"ls\"\n",
    "    \n",
    "    if write_data:\n",
    "        output = Path(f\"{sensor}_data_{country}.tif\")\n",
    "    else:\n",
    "        output = Path(f\"{sensor}_{country}.tif\")\n",
    "    geom = area.geometry\n",
    "\n",
    "    if output.exists() and not overwrite:\n",
    "        print(f\"Skipping: {country}, {output} already exists\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Working on: {country}\")\n",
    "\n",
    "    with DaskClient(n_workers=4, threads_per_worker=24, memory_limit=\"250GB\"):\n",
    "        print(\"Searching for items in area\")\n",
    "        if sentinel2:\n",
    "            items = client.search(\n",
    "                collections=[\"sentinel-2-c1-l2a\"],\n",
    "                intersects=geom,\n",
    "                datetime=year,\n",
    "            ).item_collection()\n",
    "            print(f\"Found {len(items)} items\")\n",
    "\n",
    "            data = load(\n",
    "                items,\n",
    "                geopolygon=geom,\n",
    "                measurements=[\"red\", \"green\", \"blue\", \"scl\"],\n",
    "                chunks={\"x\": 4096, \"y\": 4096},\n",
    "                groupby=\"solar_day\",\n",
    "            )\n",
    "        else:\n",
    "            configure_s3_access(cloud_defaults=True, requester_pays=True)\n",
    "\n",
    "            # Search for Landsat items\n",
    "            items = client.search(\n",
    "                collections=[\"landsat-c2-l2\"],\n",
    "                intersects=geom,\n",
    "                datetime=year,\n",
    "            ).item_collection()\n",
    "\n",
    "            # Load Landsat with ODC STAC\n",
    "            data = load(\n",
    "                items=items,\n",
    "                bbox=area.geometry.bounds,\n",
    "                bands=[\"red\", \"green\", \"blue\", \"qa_pixel\"],\n",
    "                chunks={\"x\": 4096, \"y\": 4096},\n",
    "                groupby=\"solar_day\",\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            f\"Loaded data with dimensions x: {data.x.size}, y: {data.y.size}, time: {data.time.size}\"\n",
    "        )\n",
    "\n",
    "        if sentinel2:\n",
    "            mask_flags = [0, 3, 8, 9]\n",
    "            mask = data.scl.isin(mask_flags)\n",
    "        else:\n",
    "            bitflags = 0b00011000\n",
    "            qa_mask = (data.qa_pixel & bitflags) != 0\n",
    "            nodata_mask = data.red == data.red.odc.nodata\n",
    "\n",
    "            mask = qa_mask | nodata_mask\n",
    "\n",
    "        # Clean up mask\n",
    "        filters = [(\"opening\", 4), (\"closing\", 12)]\n",
    "        filtered_mask = mask_cleanup(mask, filters)\n",
    "\n",
    "        if sentinel2:\n",
    "            masked = data.where(~filtered_mask).drop_vars(\"scl\")\n",
    "        else:\n",
    "            masked = data.where(~filtered_mask).drop_vars(\"qa_pixel\")\n",
    "\n",
    "        print(\"Computing median\")\n",
    "        median = masked.median(\"time\").compute()\n",
    "\n",
    "        if not write_data:\n",
    "            print(\"Working out percentile and making pretty picture\")\n",
    "            percentile_stretch = (1, 99)\n",
    "            rgb_array = median.to_array().values\n",
    "            vmin, vmax = nanpercentile(rgb_array, percentile_stretch)\n",
    "            visualisation = median.odc.to_rgba(vmin=vmin, vmax=vmax).compute()\n",
    "\n",
    "            visualisation.odc.write_cog(output, overwrite=True)\n",
    "            print(f\"Saved visualisation to {output}\")\n",
    "\n",
    "            return visualisation\n",
    "        else:\n",
    "            output = Path(f\"{sensor}_data_{country}.tif\")\n",
    "            median.to_array().odc.write_cog(output, overwrite=True)\n",
    "\n",
    "            print(f\"Saved data to {output}\")\n",
    "\n",
    "            return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for area in areas.itertuples():\n",
    "    visualisation = mosaic_region(area, sentinel2=True, overwrite=False, write_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
